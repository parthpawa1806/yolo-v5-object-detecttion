{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image #this is to render predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'yolov5'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parth\\Desktop\\yolov5 pytorch\\yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gitpython>=3.1.30 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from -r requirements.txt (line 5)) (3.1.31)\n",
      "Requirement already satisfied: matplotlib>=3.3 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from -r requirements.txt (line 6)) (3.5.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from -r requirements.txt (line 7)) (1.21.5)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from -r requirements.txt (line 8)) (4.8.0.74)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from -r requirements.txt (line 9)) (9.5.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from -r requirements.txt (line 10)) (5.9.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from -r requirements.txt (line 11)) (6.0)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from -r requirements.txt (line 12)) (2.28.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from -r requirements.txt (line 13)) (1.7.3)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: torch>=1.7.0 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from -r requirements.txt (line 15)) (1.13.1)\n",
      "Requirement already satisfied: torchvision>=0.8.1 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from -r requirements.txt (line 16)) (0.14.1)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from -r requirements.txt (line 17)) (4.65.0)\n",
      "Requirement already satisfied: ultralytics>=8.0.111 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from -r requirements.txt (line 18)) (8.0.126)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from -r requirements.txt (line 27)) (1.3.5)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from -r requirements.txt (line 28)) (0.12.2)\n",
      "Requirement already satisfied: setuptools>=65.5.1 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from -r requirements.txt (line 42)) (65.6.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.10)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.38.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (22.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.1.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from tqdm>=4.64.0->-r requirements.txt (line 17)) (0.4.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2023.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import IProgress\n",
    "from ipywidgets import IntProgress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.get_arch_list() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All set. Using PyTorch version 1.13.1+cpu with CPU\n"
     ]
    }
   ],
   "source": [
    "print('All set. Using PyTorch version %s with %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the yolov5 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Once all the files are cloned, you’ll need to move the dataset’s dataset.yaml file to the yolov5/data directory. \n",
    " This file contains information required by YOLO to train the model on the custom data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --img 415 --batch 3 --epochs 60 --data dataset.yaml --weights yolov5s.pt --cache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the training, two files should be saved in yolov5/runs/train/exp/weights: last.pt and best.pt. We’ll use best.pt.\n",
    "\n",
    "If you want to explore the metrics recorded during training, I suggest you use TensorBoard, a very interactive exploration tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d23c7b5d09e9831\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d23c7b5d09e9831\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model on Google Colab\n",
    "Let’s explore now how confident our model is. We can plot a validation batch obtained during training and inspect the confidence score of each label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14296\\321190626.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'runs/train/exp2/val_batch0_labels.jpg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'Image' is not defined"
     ]
    }
   ],
   "source": [
    "Image(filename='runs/train/exp2/val_batch0_labels.jpg', width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp2/weights/best.pt'], source=runs/train/exp2/test_images, data=data\\coco128.yaml, imgsz=[416, 416], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs\\detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
      "fatal: cannot change to 'C:\\Users\\parth\\Desktop\\yolov5': No such file or directory\n",
      "YOLOv5  2023-7-5 Python-3.7.16 torch-1.13.1+cpu CPU\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"detect.py\", line 261, in <module>\n",
      "    main(opt)\n",
      "  File \"detect.py\", line 256, in main\n",
      "    run(**vars(opt))\n",
      "  File \"C:\\Users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages\\torch\\autograd\\grad_mode.py\", line 27, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"detect.py\", line 98, in run\n",
      "    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)\n",
      "  File \"C:\\Users\\parth\\Desktop\\yolov5 pytorch\\yolov5\\models\\common.py\", line 344, in __init__\n",
      "    model = attempt_load(weights if isinstance(weights, list) else w, device=device, inplace=True, fuse=fuse)\n",
      "  File \"C:\\Users\\parth\\Desktop\\yolov5 pytorch\\yolov5\\models\\experimental.py\", line 79, in attempt_load\n",
      "    ckpt = torch.load(attempt_download(w), map_location='cpu')  # load\n",
      "  File \"C:\\Users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages\\torch\\serialization.py\", line 771, in load\n",
      "    with _open_file_like(f, 'rb') as opened_file:\n",
      "  File \"C:\\Users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages\\torch\\serialization.py\", line 270, in _open_file_like\n",
      "    return _open_file(name_or_buffer, mode)\n",
      "  File \"C:\\Users\\parth\\anaconda3\\envs\\parthenv\\lib\\site-packages\\torch\\serialization.py\", line 251, in __init__\n",
      "    super(_open_file, self).__init__(open(name, mode))\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'runs\\\\train\\\\exp2\\\\weights\\\\best.pt'\n"
     ]
    }
   ],
   "source": [
    "!python detect.py --weights runs/train/exp2/weights/best.pt --img 416 --conf 0.25 --source runs/train/exp2/test_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yolov5 model is trained and tested. \n",
    "\n",
    "# Now next step is to convert it into a tflite model, so that we can use it on android phone\n",
    "\n",
    "\n",
    "### you have best.pt and last.pt inside runs\\train\\exp2\\weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert weights to fp16 TFLite model\n",
    "\n",
    "!python export.py --weights runs/train/exp2/weights/best.pt --include tflite --img 416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After running the above command, you will have best-fp16.tflite in runs\\train\\exp2\\weights folder\n",
    "\n",
    "# Lets run the created tflite model.\n",
    "\n",
    "!python detect.py --weights runs\\train\\exp2\\weights\\best-fp16.tflite --img 416 --conf 0.25 --source runs/train/exp2/test_images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our model is working fine and results are stored in runs\\detect\\exp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert weights to int8 TFLite model\n",
    "\n",
    "#!python export.py --weights runs/train/exp2/weights/best.pt --include tflite --int8 --img 416 --data data/coco128.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get the android folder from here\n",
    "https://github.com/AarohiSingla/TFLite-Object-Detection-Android-App-Tutorial-Using-YOLOv5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now Put TFLite models in assets folder of Android project, and change\n",
    "\n",
    "And then open android/app/src/main/java/org/tensorflow/lite/examples/detection/tflite/DetectorFactory.java\n",
    "\n",
    "Do the following changes:\n",
    "\n",
    "Change the inputSize of image as per your dataset.\n",
    "\n",
    "Change labelFilename according to the classes of the model\n",
    "\n",
    "    \n",
    "Then run the program in Android Studio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
